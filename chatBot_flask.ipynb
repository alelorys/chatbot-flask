{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatBot flask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1J2xaGqKFgVDuY0UV1mH-EvKZw-sE0FqT",
      "authorship_tag": "ABX9TyPli6offYcooJOsiscIXWvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alelorys/chatbot-flask/blob/main/chatBot_flask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiii-6WPy2iB",
        "outputId": "f31c2aca-5a16-4816-d4ea-0e62189f8bd6"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pystempel\n",
        "!pip install transformers\n",
        "!pip install tflearn\n",
        "!pip install pyspellchecker "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting pystempel\n",
            "  Downloading pystempel-1.2.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pystempel) (4.62.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pystempel) (2.4.0)\n",
            "Installing collected packages: pystempel\n",
            "Successfully installed pystempel-1.2.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=9e1dc3c6dd4578416bd9f42686612431ddce35f1b2b1a7beb73532df9d2c583b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.2-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxs0tQK6iL8n",
        "outputId": "8da418b0-ba84-41b2-857f-52a0e74f8e41"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "import difflib\n",
        "\n",
        "import nltk\n",
        "import numpy\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.models import model_from_yaml\n",
        "from stempel import StempelStemmer\n",
        "nltk.download('punkt')\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "stemmer = StempelStemmer.polimorf()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/chatbot/q&a.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "try:\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/chatbot/chatbot.pickle\", \"rb\") as file:\n",
        "        words, labels, training, output = pickle.load(file)\n",
        "\n",
        "except:\n",
        "    words = []\n",
        "    labels = []\n",
        "    docs_x = []\n",
        "    docs_y = []\n",
        "\n",
        "    for intent in data[\"questionAnswer\"]:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            wrds = pattern.split(\" \")\n",
        "            words.extend(wrds)\n",
        "            docs_x.append(wrds)\n",
        "            docs_y.append(intent[\"tag\"])\n",
        "\n",
        "        if intent[\"tag\"] not in labels:\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "    words = sorted(list(set(words)))\n",
        "\n",
        "    labels = sorted(labels)\n",
        "\n",
        "    training = []\n",
        "    output = []\n",
        "\n",
        "    output_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "    for x, doc in enumerate(docs_x):\n",
        "        bag = []\n",
        "\n",
        "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "        for w in words:\n",
        "            if w in wrds:\n",
        "                bag.append(1)\n",
        "            else:\n",
        "                bag.append(0)\n",
        "\n",
        "        output_row = output_empty[:]\n",
        "        output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "        training.append(bag)\n",
        "        output.append(output_row)\n",
        "\n",
        "    training = numpy.array(training)\n",
        "    output = numpy.array(output)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/chatbot/chatbot.pickle\", \"wb\") as file:\n",
        "        pickle.dump((words, labels, training, output), file)\n",
        "\n",
        "try:\n",
        "    yaml_file = open('/content/drive/MyDrive/Colab Notebooks/chatbot/chatbotmodel.yaml', 'r')\n",
        "    loaded_model_yaml = yaml_file.read()\n",
        "    yaml_file.close()\n",
        "    myChatModel = model_from_yaml(loaded_model_yaml)\n",
        "    myChatModel.load_weights(\"/content/drive/MyDrive/Colab Notebooks/chatbot/chatbotmodel.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "\n",
        "except:\n",
        "    # Make our neural network\n",
        "    myChatModel = Sequential()\n",
        "    myChatModel.add(Dense(8, input_shape=[len(words)], activation='relu'))\n",
        "    myChatModel.add(Dense(len(labels), activation='softmax'))\n",
        "\n",
        "    # optimize the model\n",
        "    myChatModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # train the model\n",
        "    myChatModel.fit(training, output, epochs=1000, batch_size=8)\n",
        "\n",
        "    # serialize model to yaml and save it to disk\n",
        "    model_yaml = myChatModel.to_yaml()\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/chatbot/chatbotmodel.yaml\", \"w\") as y_file:\n",
        "        y_file.write(model_yaml)\n",
        "\n",
        "    # serialize weights to HDF5\n",
        "    myChatModel.save_weights(\"/content/drive/MyDrive/Colab Notebooks/chatbot/chatbotmodel.h5\")\n",
        "    print(\"Saved model from disk\")\n",
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = s.split(\" \")\n",
        "\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "          seq = difflib.SequenceMatcher(None,w,se)\n",
        "          d = seq.ratio()*100\n",
        "          if w == se:\n",
        "            bag[i] = 1\n",
        "          if d >= 75:\n",
        "            bag[i] = 1\n",
        "          \n",
        "         \n",
        "            \n",
        "    return numpy.array(bag)\n",
        "\n",
        "def chatWithBot(userMess):\n",
        "    currentText = bag_of_words(userMess, words)\n",
        "    currentTextArray = [currentText]\n",
        "    numpyCurrentText = numpy.array(currentTextArray)\n",
        "    if numpy.all((numpyCurrentText == 0)):\n",
        "      answer = \"Nie rozumiem, zadaj pytanie jeszcze raz!\"\n",
        "      return answer\n",
        "\n",
        "    result = myChatModel.predict(numpyCurrentText[0:1])\n",
        "    result_index = numpy.argmax(result)\n",
        "    tag = labels[result_index]\n",
        "    if result[0][result_index] > 0.6:\n",
        "        for tg in data[\"questionAnswer\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        answer = random.choice(responses)\n",
        "        return answer\n",
        "\n",
        "    else:\n",
        "        answer = \"Nie rozumiem, zadaj pytanie jeszcze raz!\"\n",
        "        return answer\n",
        "\n",
        "def chat(userMess):\n",
        "    \n",
        "\n",
        "    while True:\n",
        "        inp = userMess\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "        if inp.lower() == \"\" or inp.lower() == \" \":\n",
        "          answer = \"Musisz coś napisać!\"\n",
        "          return answer\n",
        "        \n",
        "        return chatWithBot(inp)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/get\")\n",
        "def get_bot_response():\n",
        "    userMess = request.args.get(\"msg\")\n",
        "    return chat(userMess)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading: 100%|██████████| 11368252/11368252 [08:58<00:00, 21129.68bytes/s] \n",
            "Loading:  99%|█████████▉| 11302016/11368252 [00:14<00:00, 455785.47bytes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://303eb8ddbb0c.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [17/Aug/2021 07:46:06] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:46:07] \"\u001b[33mGET /static/style.css HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:46:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "Loading: 100%|██████████| 11368252/11368252 [00:26<00:00, 455785.47bytes/s]127.0.0.1 - - [17/Aug/2021 07:46:21] \"\u001b[37mGET /get?msg=dzien%20dobry HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:46:26] \"\u001b[37mGET /get?msg= HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:46:39] \"\u001b[37mGET /get?msg=Kiedy%20zaczynaja%20się%20zajęcia HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:46:55] \"\u001b[37mGET /get?msg=Jak%20można%20dojechać%20do%20akademii%3F HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:47:07] \"\u001b[37mGET /get?msg=Jak%20wyglada%20nauka HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [17/Aug/2021 07:47:13] \"\u001b[37mGET /get?msg=Dziękuje HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrQ9dwK15Zs6",
        "outputId": "36e6e65c-b18e-479f-b321-d2037cedec2e"
      },
      "source": [
        "def chat(userMess):\n",
        "    \n",
        "    while True:\n",
        "        inp = userMess\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "        if inp.lower() == \"\":\n",
        "          responses = \"Musisz coś napisać\"\n",
        "          #print(\"Czesio: Musisz coś napisać!\")\n",
        "        else:\n",
        "          results = model.predict([bag_of_words(inp, words)])\n",
        "          results_index = numpy.argmax(results)\n",
        "          tag = labels[results_index]\n",
        "\n",
        "          for tg in data[\"questionAnswer\"]:\n",
        "              if tg['tag'] == tag:\n",
        "                  responses = tg['responses']\n",
        "              \n",
        "\n",
        "          answer = random.choice(responses)\n",
        "\n",
        "        return answer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}